{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Sqooler","text":"<p>This is a collection of cold atom simulators that you can access through the <code>qiskit-cold-atom</code> and the <code>qlued</code> interface:</p> <ul> <li><code>qiskit-cold-atom</code> allows the enduser to write the circuit definitions on its laptop and send them to the server in form of a nice json file.</li> <li><code>qlued</code> handles the user management and stores the received json file in an appropiate queue.</li> <li><code>sqooler</code> acts as the backend that performs the calculations from the queue and sends back the result into the storage.</li> </ul> <p>To enable this work-flow, the simulator has to follow a few rules on how to parse the json files etc. This is what we have started to standardize and simplify as much as possible. In the following we documented each module its purpose and look forward to your contributions.</p>"},{"location":"#getting-started-on-heroku","title":"Getting started on heroku","text":"<p>The simplest way to use the package is to deploy it to <code>heroku</code>. This directly starts the <code>maintainer.py</code> in a loop, because it is defined like that in the <code>Procfile</code>.  However, you will also need to have the following credentials of the Dropbox:</p> <ul> <li><code>APP_KEY</code>, <code>APP_SECRET</code> and <code>REFRESH_TOKEN</code>. Please head over to the documentation of <code>qlued</code> to see how they might be set up.</li> <li>They should be all defined <code>Settings</code> &gt; <code>Config Vars</code>. </li> <li>Now your system  should automatically look for jobs that are under <code>Backend_files/Queued_Jobs</code>, process them and safe the result under <code>Backend_files/Finished_Jobs</code>.</li> </ul>"},{"location":"#getting-started-locally","title":"Getting started locally","text":"<p>Note</p> <p>This part of the documentiation needs a lot of love. Feel free to help us making it more understandable.</p> <p>If you would like to write some new simulator, extend it etc, you will need to deploy the code locally. Then you will need to:</p> <ul> <li>clone or fork the repo.</li> <li>pip install the <code>requirements.txt</code>.</li> <li>define <code>APP_KEY</code>, <code>APP_SECRET</code> and <code>REFRESH_TOKEN</code> in the <code>.env</code> file that is you should create in the root directory.</li> </ul>"},{"location":"#first-steps","title":"First steps","text":"<p>The whole system is set up on <code>python</code>. First, create a local environment. You can then install the requirements via <code>pip install -r requirements-dev.txt</code>.</p> <p>Second, we need to enable the storage of the settings, which we manage with python-decouple. To do so, create a <code>.env</code> file in the root directory.  <pre><code>project\n\u2502   README.md\n\u2502   maintainer.py\n|   .env\n|   ...    \n\u2502\n\u2514\u2500\u2500\u2500.github\n\u2502   \u2502   ...\n|\n\u2514\u2500\u2500\u2500utils\n\u2502   \u2502   ...\n|\n\u2502   ...\n</code></pre></p> <p>An example content of this file would be:</p> <pre><code># setting for MongoDB\nMONGODB_USERNAME = &lt;YOUR-USERNAME&gt;\nMONGODB_PASSWORD = &lt;YOUR-PASSWORD&gt;\nMONGODB_DATABASE_URL = &lt;YOUR-URL&gt;\n\n# settings for the Dropbox, if you use it as a storage\nAPP_KEY=&lt;YOUR-APP-KEY&gt;\nAPP_SECRET=&lt;YOUR-APP-SECRED&gt;\nREFRESH_TOKEN=&lt;YOUR-REFRESH-TOKEN&gt;\n</code></pre> <p>Then, to configure the storage make sure which one you use as we provide different options. For example, if you use the MongoDB storage you have to set the <code>MONGODB_USERNAME</code>, <code>MONGODB_PASSWORD</code> and <code>MONGODB_DATABASE_URL</code>.</p> <p>If you use the Dropbox storage, add the <code>APP_KEY</code>, <code>APP_SECRET</code> and <code>REFRESH_TOKEN</code> to the <code>.env</code> file.</p> <p>To run the system you should run the <code>maintainer</code> with <code>python maintainer.py</code>.</p> <p>Note</p> <p>This step also uploads the configuration of the backends onto the storage. So it is crucial for any kind of tests that involve <code>qlued</code>.</p> <p>You can now also stop the maintainer and test the system systematically. This can be performed via <code>python - m pytest</code>.</p>"},{"location":"utils/","title":"Utils","text":"<p>This is the module that contains all the basic logic to read the json files that come from <code>qlued</code>. It also allows for validation etc. So if you are not a developer that tries to extend the core behavior of the <code>sqooler</code> it is unlikely that you should modify this part of the code. However, it is instructive to have a look below to understand the  modules that are provided for the creation of a simulator.</p> <p>Below you can find the API of the <code>utils</code>.</p>"},{"location":"utils/#storage-providers","title":"Storage Providers","text":"<p>The module that contains all the necessary logic for communication with the external storage for the jobs. It creates an abstract API layer for the storage providers.</p>"},{"location":"utils/#src.sqooler.storage_providers.DropboxProvider","title":"<code>DropboxProvider</code>","text":"<p>             Bases: <code>StorageProvider</code></p> <p>The class that implements the dropbox storage provider.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>class DropboxProvider(StorageProvider):\n    \"\"\"\n    The class that implements the dropbox storage provider.\n    \"\"\"\n\n    def __init__(self, login_dict: DropboxLoginInformation) -&gt; None:\n        \"\"\"\n        Set up the neccessary keys.\n        \"\"\"\n        self.app_key = login_dict.app_key\n        self.app_secret = login_dict.app_secret\n        self.refresh_token = login_dict.refresh_token\n\n    def upload(self, content_dict: Mapping, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Upload the content_dict as a json file to the dropbox\n\n        Args:\n            content_dict: the content of the file that should be uploaded\n            storage_path: the path where the file should be stored, but excluding the file name\n            job_id: the name of the file without the .json extension\n        \"\"\"\n\n        # create the appropriate string for the dropbox API\n        dump_str = json.dumps(content_dict)\n\n        # strip trailing and leading slashes from the storage_path\n        storage_path = storage_path.strip(\"/\")\n\n        # create the full path\n        full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n\n        # Create an instance of a Dropbox class, which can make requests to the API.\n        with dropbox.Dropbox(\n            app_key=self.app_key,\n            app_secret=self.app_secret,\n            oauth2_refresh_token=self.refresh_token,\n        ) as dbx:\n            # Check that the access token is valid\n            dbx.users_get_current_account()\n            dbx.files_upload(\n                dump_str.encode(\"utf-8\"), full_path, mode=WriteMode(\"overwrite\")\n            )\n\n    def get_file_content(self, storage_path: str, job_id: str) -&gt; dict:\n        \"\"\"\n        Get the file content from the dropbox\n\n        storage_path: the path where the file should be stored, but excluding the file name\n        job_id: the name of the file. Is a json file\n        \"\"\"\n\n        # strip trailing and leading slashes from the storage_path\n        storage_path = storage_path.strip(\"/\")\n\n        # Create an instance of a Dropbox class, which can make requests to the API.\n        with dropbox.Dropbox(\n            app_key=self.app_key,\n            app_secret=self.app_secret,\n            oauth2_refresh_token=self.refresh_token,\n        ) as dbx:\n            # Check that the access token is valid\n            try:\n                dbx.users_get_current_account()\n            except AuthError:\n                sys.exit(\"ERROR: Invalid access token.\")\n            full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n            _, res = dbx.files_download(path=full_path)\n            data = res.content\n        return json.loads(data.decode(\"utf-8\"))\n\n    def get_job_content(self, storage_path: str, job_id: str) -&gt; dict:\n        \"\"\"\n        Get the content of the job from the storage. This is a wrapper around get_file_content\n        and and handles the different ways of identifiying the job.\n\n        storage_path: the path towards the file, excluding the filename / id\n        job_id: the id of the file we are about to look up\n\n        Returns:\n            The content of the job\n        \"\"\"\n        return self.get_file_content(storage_path=storage_path, job_id=f\"job-{job_id}\")\n\n    def update_file(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Update the file content.\n\n        Args:\n            content_dict: The dictionary containing the new content of the file\n            storage_path: The path to the file\n            job_id: The id of the job\n\n        Returns:\n            None\n        \"\"\"\n        # create the appropriate string for the dropbox API\n        dump_str = json.dumps(content_dict)\n\n        # strip trailing and leading slashes from the storage_path\n        storage_path = storage_path.strip(\"/\")\n\n        # create the full path\n        full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n\n        # Create an instance of a Dropbox class, which can make requests to the API.\n        with dropbox.Dropbox(\n            app_key=self.app_key,\n            app_secret=self.app_secret,\n            oauth2_refresh_token=self.refresh_token,\n        ) as dbx:\n            # Check that the access token is valid\n            dbx.users_get_current_account()\n            dbx.files_upload(\n                dump_str.encode(\"utf-8\"), full_path, mode=WriteMode(\"overwrite\")\n            )\n\n    def move_file(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Move the file from start_path to final_path\n\n        start_path: the path where the file is currently stored, but excluding the file name\n        final_path: the path where the file should be stored, but excluding the file name\n        job_id: the name of the file. Is a json file\n\n        Returns:\n            None\n        \"\"\"\n        # strip trailing and leading slashes from the paths\n        start_path = start_path.strip(\"/\")\n        final_path = final_path.strip(\"/\")\n\n        # Create an instance of a Dropbox class, which can make requests to the API.\n        with dropbox.Dropbox(\n            app_key=self.app_key,\n            app_secret=self.app_secret,\n            oauth2_refresh_token=self.refresh_token,\n        ) as dbx:\n            dbx.users_get_current_account()\n\n            full_start_path = \"/\" + start_path + \"/\" + job_id + \".json\"\n            full_final_path = \"/\" + final_path + \"/\" + job_id + \".json\"\n            dbx.files_move_v2(full_start_path, full_final_path)\n\n    def delete_file(self, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Remove the file from the dropbox\n\n        Args:\n            storage_path: the path where the file should be stored, but excluding the file name\n            job_id: the name of the file. Is a json file\n\n        Returns:\n            None\n        \"\"\"\n\n        # strip trailing and leading slashes from the storage_path\n        storage_path = storage_path.strip(\"/\")\n\n        # Create an instance of a Dropbox class, which can make requests to the API.\n        with dropbox.Dropbox(\n            app_key=self.app_key,\n            app_secret=self.app_secret,\n            oauth2_refresh_token=self.refresh_token,\n        ) as dbx:\n            # Check that the access token is valid\n            try:\n                dbx.users_get_current_account()\n            except AuthError:\n                sys.exit(\"ERROR: Invalid access token.\")\n\n            full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n            _ = dbx.files_delete(path=full_path)\n\n    def upload_config(self, config_dict: dict, backend_name: str) -&gt; None:\n        \"\"\"\n        The function that uploads the spooler configuration to the storage.\n\n        All the configurations are stored in the Backend_files/Config folder.\n        For each backend there is a separate folder in which the configuration is stored as a json file.\n\n        Args:\n            config_dict: The dictionary containing the configuration\n            backend_name (str): The name of the backend\n\n        Returns:\n            None\n        \"\"\"\n\n        config_path = \"Backend_files/Config/\" + backend_name\n        self.upload(config_dict, config_path, \"config\")\n\n    def update_in_database(\n        self,\n        result_dict: ResultDict,\n        status_msg_dict: dict,\n        job_id: str,\n        backend_name: str,\n    ) -&gt; None:\n        \"\"\"\n        Upload the status and result to the dropbox.\n\n        Args:\n            result_dict: the dictionary containing the result of the job\n            status_msg_dict: the dictionary containing the status message of the job\n            job_id: the name of the job\n            backend_name: the name of the backend\n\n        Returns:\n            None\n        \"\"\"\n        # this should become part of the json file instead of its name in the future\n        extracted_username = job_id.split(\"-\")[2]\n\n        status_json_dir = (\n            \"/Backend_files/Status/\" + backend_name + \"/\" + extracted_username + \"/\"\n        )\n        status_json_name = \"status-\" + job_id\n\n        job_json_name = \"job-\" + job_id\n        job_json_start_dir = \"Backend_files/Running_Jobs\"\n\n        if status_msg_dict[\"status\"] == \"DONE\":\n            # let us create the result json file\n            result_json_dir = (\n                \"/Backend_files/Result/\" + backend_name + \"/\" + extracted_username + \"/\"\n            )\n            result_json_name = \"result-\" + job_id\n            self.upload(result_dict, result_json_dir, result_json_name)\n\n            # now move the job out of the running jobs into the finished jobs\n            job_finished_json_dir = (\n                \"/Backend_files/Finished_Jobs/\"\n                + backend_name\n                + \"/\"\n                + extracted_username\n                + \"/\"\n            )\n            self.move_file(job_json_start_dir, job_finished_json_dir, job_json_name)\n\n        elif status_msg_dict[\"status\"] == \"ERROR\":\n            # because there was an error, we move the job to the deleted jobs\n            deleted_json_dir = \"Backend_files/Deleted_Jobs\"\n            self.move_file(job_json_start_dir, deleted_json_dir, job_json_name)\n\n        # and create the status json file\n        self.upload(status_msg_dict, status_json_dir, status_json_name)\n\n    def get_file_queue(self, storage_path: str) -&gt; list[str]:\n        \"\"\"\n        Get a list of files. Typically we are looking for the queued jobs of a backend here.\n\n        Args:\n            storage_path: Where are we looking for the files.\n\n        Returns:\n            A list of files that was found.\n        \"\"\"\n\n        # strip trailing and leading slashes from the paths\n        storage_path = storage_path.strip(\"/\")\n\n        storage_path = \"/\" + storage_path.strip(\"/\") + \"/\"\n\n        # Create an instance of a Dropbox class, which can make requests to the API.\n        file_list = []\n        with dropbox.Dropbox(\n            app_key=self.app_key,\n            app_secret=self.app_secret,\n            oauth2_refresh_token=self.refresh_token,\n        ) as dbx:\n            # Check that the access token is valid\n            try:\n                dbx.users_get_current_account()\n            except AuthError:\n                sys.exit(\"ERROR: Invalid access token.\")\n            # We should really handle these exceptions cleaner, but this seems a bit\n            # complicated right now\n            # pylint: disable=W0703\n            try:\n                response = dbx.files_list_folder(path=storage_path)\n                file_list = response.entries\n                file_list = [item.name for item in file_list]\n            except ApiError:\n                print(f\"Could not obtain job queue for {storage_path}\")\n            except Exception as err:\n                print(err)\n        return file_list\n\n    def get_next_job_in_queue(self, backend_name: str) -&gt; dict:\n        \"\"\"\n        A function that obtains the next job in the queue.\n\n        Args:\n            backend_name (str): The name of the backend\n\n        Returns:\n            the path towards the job\n        \"\"\"\n        job_json_dir = \"/Backend_files/Queued_Jobs/\" + backend_name + \"/\"\n        job_dict = {\"job_id\": 0, \"job_json_path\": \"None\"}\n        job_list = self.get_file_queue(job_json_dir)\n        # if there is a job, we should move it\n        if job_list:\n            job_json_name = job_list[0]\n            job_dict[\"job_id\"] = job_json_name[4:-5]\n\n            # split the .json from the job_json_name\n            job_json_name = job_json_name.split(\".\")[0]\n            # and move the file into the right directory\n            self.move_file(job_json_dir, \"Backend_files/Running_Jobs\", job_json_name)\n            job_dict[\"job_json_path\"] = \"Backend_files/Running_Jobs\"\n        return job_dict\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.DropboxProvider.__init__","title":"<code>__init__(login_dict)</code>","text":"<p>Set up the neccessary keys.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def __init__(self, login_dict: DropboxLoginInformation) -&gt; None:\n    \"\"\"\n    Set up the neccessary keys.\n    \"\"\"\n    self.app_key = login_dict.app_key\n    self.app_secret = login_dict.app_secret\n    self.refresh_token = login_dict.refresh_token\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.DropboxProvider.delete_file","title":"<code>delete_file(storage_path, job_id)</code>","text":"<p>Remove the file from the dropbox</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>the path where the file should be stored, but excluding the file name</p> required <code>job_id</code> <code>str</code> <p>the name of the file. Is a json file</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def delete_file(self, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Remove the file from the dropbox\n\n    Args:\n        storage_path: the path where the file should be stored, but excluding the file name\n        job_id: the name of the file. Is a json file\n\n    Returns:\n        None\n    \"\"\"\n\n    # strip trailing and leading slashes from the storage_path\n    storage_path = storage_path.strip(\"/\")\n\n    # Create an instance of a Dropbox class, which can make requests to the API.\n    with dropbox.Dropbox(\n        app_key=self.app_key,\n        app_secret=self.app_secret,\n        oauth2_refresh_token=self.refresh_token,\n    ) as dbx:\n        # Check that the access token is valid\n        try:\n            dbx.users_get_current_account()\n        except AuthError:\n            sys.exit(\"ERROR: Invalid access token.\")\n\n        full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n        _ = dbx.files_delete(path=full_path)\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.DropboxProvider.get_file_content","title":"<code>get_file_content(storage_path, job_id)</code>","text":"<p>Get the file content from the dropbox</p> <p>storage_path: the path where the file should be stored, but excluding the file name job_id: the name of the file. Is a json file</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_file_content(self, storage_path: str, job_id: str) -&gt; dict:\n    \"\"\"\n    Get the file content from the dropbox\n\n    storage_path: the path where the file should be stored, but excluding the file name\n    job_id: the name of the file. Is a json file\n    \"\"\"\n\n    # strip trailing and leading slashes from the storage_path\n    storage_path = storage_path.strip(\"/\")\n\n    # Create an instance of a Dropbox class, which can make requests to the API.\n    with dropbox.Dropbox(\n        app_key=self.app_key,\n        app_secret=self.app_secret,\n        oauth2_refresh_token=self.refresh_token,\n    ) as dbx:\n        # Check that the access token is valid\n        try:\n            dbx.users_get_current_account()\n        except AuthError:\n            sys.exit(\"ERROR: Invalid access token.\")\n        full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n        _, res = dbx.files_download(path=full_path)\n        data = res.content\n    return json.loads(data.decode(\"utf-8\"))\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.DropboxProvider.get_file_queue","title":"<code>get_file_queue(storage_path)</code>","text":"<p>Get a list of files. Typically we are looking for the queued jobs of a backend here.</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>Where are we looking for the files.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of files that was found.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_file_queue(self, storage_path: str) -&gt; list[str]:\n    \"\"\"\n    Get a list of files. Typically we are looking for the queued jobs of a backend here.\n\n    Args:\n        storage_path: Where are we looking for the files.\n\n    Returns:\n        A list of files that was found.\n    \"\"\"\n\n    # strip trailing and leading slashes from the paths\n    storage_path = storage_path.strip(\"/\")\n\n    storage_path = \"/\" + storage_path.strip(\"/\") + \"/\"\n\n    # Create an instance of a Dropbox class, which can make requests to the API.\n    file_list = []\n    with dropbox.Dropbox(\n        app_key=self.app_key,\n        app_secret=self.app_secret,\n        oauth2_refresh_token=self.refresh_token,\n    ) as dbx:\n        # Check that the access token is valid\n        try:\n            dbx.users_get_current_account()\n        except AuthError:\n            sys.exit(\"ERROR: Invalid access token.\")\n        # We should really handle these exceptions cleaner, but this seems a bit\n        # complicated right now\n        # pylint: disable=W0703\n        try:\n            response = dbx.files_list_folder(path=storage_path)\n            file_list = response.entries\n            file_list = [item.name for item in file_list]\n        except ApiError:\n            print(f\"Could not obtain job queue for {storage_path}\")\n        except Exception as err:\n            print(err)\n    return file_list\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.DropboxProvider.get_job_content","title":"<code>get_job_content(storage_path, job_id)</code>","text":"<p>Get the content of the job from the storage. This is a wrapper around get_file_content and and handles the different ways of identifiying the job.</p> <p>storage_path: the path towards the file, excluding the filename / id job_id: the id of the file we are about to look up</p> <p>Returns:</p> Type Description <code>dict</code> <p>The content of the job</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_job_content(self, storage_path: str, job_id: str) -&gt; dict:\n    \"\"\"\n    Get the content of the job from the storage. This is a wrapper around get_file_content\n    and and handles the different ways of identifiying the job.\n\n    storage_path: the path towards the file, excluding the filename / id\n    job_id: the id of the file we are about to look up\n\n    Returns:\n        The content of the job\n    \"\"\"\n    return self.get_file_content(storage_path=storage_path, job_id=f\"job-{job_id}\")\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.DropboxProvider.get_next_job_in_queue","title":"<code>get_next_job_in_queue(backend_name)</code>","text":"<p>A function that obtains the next job in the queue.</p> <p>Parameters:</p> Name Type Description Default <code>backend_name</code> <code>str</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>dict</code> <p>the path towards the job</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_next_job_in_queue(self, backend_name: str) -&gt; dict:\n    \"\"\"\n    A function that obtains the next job in the queue.\n\n    Args:\n        backend_name (str): The name of the backend\n\n    Returns:\n        the path towards the job\n    \"\"\"\n    job_json_dir = \"/Backend_files/Queued_Jobs/\" + backend_name + \"/\"\n    job_dict = {\"job_id\": 0, \"job_json_path\": \"None\"}\n    job_list = self.get_file_queue(job_json_dir)\n    # if there is a job, we should move it\n    if job_list:\n        job_json_name = job_list[0]\n        job_dict[\"job_id\"] = job_json_name[4:-5]\n\n        # split the .json from the job_json_name\n        job_json_name = job_json_name.split(\".\")[0]\n        # and move the file into the right directory\n        self.move_file(job_json_dir, \"Backend_files/Running_Jobs\", job_json_name)\n        job_dict[\"job_json_path\"] = \"Backend_files/Running_Jobs\"\n    return job_dict\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.DropboxProvider.move_file","title":"<code>move_file(start_path, final_path, job_id)</code>","text":"<p>Move the file from start_path to final_path</p> <p>start_path: the path where the file is currently stored, but excluding the file name final_path: the path where the file should be stored, but excluding the file name job_id: the name of the file. Is a json file</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def move_file(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Move the file from start_path to final_path\n\n    start_path: the path where the file is currently stored, but excluding the file name\n    final_path: the path where the file should be stored, but excluding the file name\n    job_id: the name of the file. Is a json file\n\n    Returns:\n        None\n    \"\"\"\n    # strip trailing and leading slashes from the paths\n    start_path = start_path.strip(\"/\")\n    final_path = final_path.strip(\"/\")\n\n    # Create an instance of a Dropbox class, which can make requests to the API.\n    with dropbox.Dropbox(\n        app_key=self.app_key,\n        app_secret=self.app_secret,\n        oauth2_refresh_token=self.refresh_token,\n    ) as dbx:\n        dbx.users_get_current_account()\n\n        full_start_path = \"/\" + start_path + \"/\" + job_id + \".json\"\n        full_final_path = \"/\" + final_path + \"/\" + job_id + \".json\"\n        dbx.files_move_v2(full_start_path, full_final_path)\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.DropboxProvider.update_file","title":"<code>update_file(content_dict, storage_path, job_id)</code>","text":"<p>Update the file content.</p> <p>Parameters:</p> Name Type Description Default <code>content_dict</code> <code>dict</code> <p>The dictionary containing the new content of the file</p> required <code>storage_path</code> <code>str</code> <p>The path to the file</p> required <code>job_id</code> <code>str</code> <p>The id of the job</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def update_file(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Update the file content.\n\n    Args:\n        content_dict: The dictionary containing the new content of the file\n        storage_path: The path to the file\n        job_id: The id of the job\n\n    Returns:\n        None\n    \"\"\"\n    # create the appropriate string for the dropbox API\n    dump_str = json.dumps(content_dict)\n\n    # strip trailing and leading slashes from the storage_path\n    storage_path = storage_path.strip(\"/\")\n\n    # create the full path\n    full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n\n    # Create an instance of a Dropbox class, which can make requests to the API.\n    with dropbox.Dropbox(\n        app_key=self.app_key,\n        app_secret=self.app_secret,\n        oauth2_refresh_token=self.refresh_token,\n    ) as dbx:\n        # Check that the access token is valid\n        dbx.users_get_current_account()\n        dbx.files_upload(\n            dump_str.encode(\"utf-8\"), full_path, mode=WriteMode(\"overwrite\")\n        )\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.DropboxProvider.update_in_database","title":"<code>update_in_database(result_dict, status_msg_dict, job_id, backend_name)</code>","text":"<p>Upload the status and result to the dropbox.</p> <p>Parameters:</p> Name Type Description Default <code>result_dict</code> <code>ResultDict</code> <p>the dictionary containing the result of the job</p> required <code>status_msg_dict</code> <code>dict</code> <p>the dictionary containing the status message of the job</p> required <code>job_id</code> <code>str</code> <p>the name of the job</p> required <code>backend_name</code> <code>str</code> <p>the name of the backend</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def update_in_database(\n    self,\n    result_dict: ResultDict,\n    status_msg_dict: dict,\n    job_id: str,\n    backend_name: str,\n) -&gt; None:\n    \"\"\"\n    Upload the status and result to the dropbox.\n\n    Args:\n        result_dict: the dictionary containing the result of the job\n        status_msg_dict: the dictionary containing the status message of the job\n        job_id: the name of the job\n        backend_name: the name of the backend\n\n    Returns:\n        None\n    \"\"\"\n    # this should become part of the json file instead of its name in the future\n    extracted_username = job_id.split(\"-\")[2]\n\n    status_json_dir = (\n        \"/Backend_files/Status/\" + backend_name + \"/\" + extracted_username + \"/\"\n    )\n    status_json_name = \"status-\" + job_id\n\n    job_json_name = \"job-\" + job_id\n    job_json_start_dir = \"Backend_files/Running_Jobs\"\n\n    if status_msg_dict[\"status\"] == \"DONE\":\n        # let us create the result json file\n        result_json_dir = (\n            \"/Backend_files/Result/\" + backend_name + \"/\" + extracted_username + \"/\"\n        )\n        result_json_name = \"result-\" + job_id\n        self.upload(result_dict, result_json_dir, result_json_name)\n\n        # now move the job out of the running jobs into the finished jobs\n        job_finished_json_dir = (\n            \"/Backend_files/Finished_Jobs/\"\n            + backend_name\n            + \"/\"\n            + extracted_username\n            + \"/\"\n        )\n        self.move_file(job_json_start_dir, job_finished_json_dir, job_json_name)\n\n    elif status_msg_dict[\"status\"] == \"ERROR\":\n        # because there was an error, we move the job to the deleted jobs\n        deleted_json_dir = \"Backend_files/Deleted_Jobs\"\n        self.move_file(job_json_start_dir, deleted_json_dir, job_json_name)\n\n    # and create the status json file\n    self.upload(status_msg_dict, status_json_dir, status_json_name)\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.DropboxProvider.upload","title":"<code>upload(content_dict, storage_path, job_id)</code>","text":"<p>Upload the content_dict as a json file to the dropbox</p> <p>Parameters:</p> Name Type Description Default <code>content_dict</code> <code>Mapping</code> <p>the content of the file that should be uploaded</p> required <code>storage_path</code> <code>str</code> <p>the path where the file should be stored, but excluding the file name</p> required <code>job_id</code> <code>str</code> <p>the name of the file without the .json extension</p> required Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def upload(self, content_dict: Mapping, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Upload the content_dict as a json file to the dropbox\n\n    Args:\n        content_dict: the content of the file that should be uploaded\n        storage_path: the path where the file should be stored, but excluding the file name\n        job_id: the name of the file without the .json extension\n    \"\"\"\n\n    # create the appropriate string for the dropbox API\n    dump_str = json.dumps(content_dict)\n\n    # strip trailing and leading slashes from the storage_path\n    storage_path = storage_path.strip(\"/\")\n\n    # create the full path\n    full_path = \"/\" + storage_path + \"/\" + job_id + \".json\"\n\n    # Create an instance of a Dropbox class, which can make requests to the API.\n    with dropbox.Dropbox(\n        app_key=self.app_key,\n        app_secret=self.app_secret,\n        oauth2_refresh_token=self.refresh_token,\n    ) as dbx:\n        # Check that the access token is valid\n        dbx.users_get_current_account()\n        dbx.files_upload(\n            dump_str.encode(\"utf-8\"), full_path, mode=WriteMode(\"overwrite\")\n        )\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.DropboxProvider.upload_config","title":"<code>upload_config(config_dict, backend_name)</code>","text":"<p>The function that uploads the spooler configuration to the storage.</p> <p>All the configurations are stored in the Backend_files/Config folder. For each backend there is a separate folder in which the configuration is stored as a json file.</p> <p>Parameters:</p> Name Type Description Default <code>config_dict</code> <code>dict</code> <p>The dictionary containing the configuration</p> required <code>backend_name</code> <code>str</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def upload_config(self, config_dict: dict, backend_name: str) -&gt; None:\n    \"\"\"\n    The function that uploads the spooler configuration to the storage.\n\n    All the configurations are stored in the Backend_files/Config folder.\n    For each backend there is a separate folder in which the configuration is stored as a json file.\n\n    Args:\n        config_dict: The dictionary containing the configuration\n        backend_name (str): The name of the backend\n\n    Returns:\n        None\n    \"\"\"\n\n    config_path = \"Backend_files/Config/\" + backend_name\n    self.upload(config_dict, config_path, \"config\")\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.LocalProvider","title":"<code>LocalProvider</code>","text":"<p>             Bases: <code>StorageProvider</code></p> <p>Create a file storage that works on the local machine.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>class LocalProvider(StorageProvider):\n    \"\"\"\n    Create a file storage that works on the local machine.\n    \"\"\"\n\n    def __init__(self, login_dict: LocalLoginInformation) -&gt; None:\n        \"\"\"\n        Set up the neccessary keys and create the client through which all the connections will run.\n        \"\"\"\n        self.base_path = login_dict.base_path\n\n    def upload(self, content_dict: Mapping, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Upload the file to the storage\n        \"\"\"\n        # strip trailing and leading slashes from the storage_path\n        storage_path = storage_path.strip(\"/\")\n\n        # json folder\n        folder_path = self.base_path + \"/\" + storage_path\n        if not os.path.exists(folder_path):\n            os.makedirs(folder_path)\n\n        # create the full path\n        full_json_path = folder_path + \"/\" + job_id + \".json\"\n\n        with open(full_json_path, \"w\", encoding=\"utf-8\") as json_file:\n            json.dump(content_dict, json_file)\n\n    def get_file_content(self, storage_path: str, job_id: str) -&gt; dict:\n        \"\"\"\n        Get the file content from the storage\n        \"\"\"\n        # strip trailing and leading slashes from the storage_path\n        storage_path = storage_path.strip(\"/\")\n\n        # create the full path\n        full_json_path = self.base_path + \"/\" + storage_path + \"/\" + job_id + \".json\"\n\n        with open(full_json_path, \"r\", encoding=\"utf-8\") as json_file:\n            loaded_data_dict = json.load(json_file)\n        return loaded_data_dict\n\n    def get_job_content(self, storage_path: str, job_id: str) -&gt; dict:\n        \"\"\"\n        Get the content of the job from the storage. This is a wrapper around get_file_content\n        and and handles the different ways of identifiying the job.\n\n        storage_path: the path towards the file, excluding the filename / id\n        job_id: the id of the file we are about to look up\n\n        Returns:\n            The content of the job\n        \"\"\"\n        job_dict = self.get_file_content(storage_path=storage_path, job_id=job_id)\n        return job_dict\n\n    def update_file(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Update the file content.\n\n        Args:\n            content_dict: The dictionary containing the new content of the file\n            storage_path: The path to the file\n            job_id: The id of the job\n\n        Returns:\n            None\n        \"\"\"\n        # strip trailing and leading slashes from the storage_path\n        storage_path = storage_path.strip(\"/\")\n\n        # json folder\n        folder_path = self.base_path + \"/\" + storage_path\n\n        # create the full path\n        full_json_path = folder_path + \"/\" + job_id + \".json\"\n\n        # does the file already exist ?\n        if not os.path.exists(full_json_path):\n            raise FileNotFoundError(\n                f\"The file {full_json_path} does not exist and cannot be updated.\"\n            )\n        with open(full_json_path, \"w\", encoding=\"utf-8\") as json_file:\n            json.dump(content_dict, json_file)\n\n    def move_file(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Move the file from `start_path` to `final_path`\n        \"\"\"\n        start_path = start_path.strip(\"/\")\n\n        source_file = self.base_path + \"/\" + start_path + \"/\" + job_id + \".json\"\n        final_path = self.base_path + \"/\" + final_path + \"/\"\n        if not os.path.exists(final_path):\n            os.makedirs(final_path)\n\n        # Move the file\n        shutil.move(source_file, final_path)\n\n    def delete_file(self, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Delete the file from the storage\n\n        Args:\n            storage_path: the path where the file is currently stored, but excluding the file name\n            job_id: the name of the file\n\n        Returns:\n            None\n        \"\"\"\n        storage_path = storage_path.strip(\"/\")\n        source_file = self.base_path + \"/\" + storage_path + \"/\" + job_id + \".json\"\n        os.remove(source_file)\n\n    def upload_config(self, config_dict: dict, backend_name: str) -&gt; None:\n        \"\"\"\n        The function that uploads the spooler configuration to the storage.\n\n        Args:\n            config_dict: The dictionary containing the configuration\n            backend_name (str): The name of the backend\n\n        Returns:\n            None\n        \"\"\"\n        # path of the configs\n        config_path = self.base_path + \"/backends/configs\"\n        # test if the config path already exists. If it does not, create it\n        if not os.path.exists(config_path):\n            os.makedirs(config_path)\n\n        full_json_path = config_path + \"/\" + backend_name + \".json\"\n        with open(full_json_path, \"w\", encoding=\"utf-8\") as json_file:\n            json.dump(config_dict, json_file)\n\n    def update_in_database(\n        self,\n        result_dict: ResultDict,\n        status_msg_dict: dict,\n        job_id: str,\n        backend_name: str,\n    ) -&gt; None:\n        \"\"\"\n        Upload the status and result to the `StorageProvider`.\n\n        Args:\n            result_dict: the dictionary containing the result of the job\n            status_msg_dict: the dictionary containing the status message of the job\n            job_id: the name of the job\n            backend_name: the name of the backend\n\n        Returns:\n            None\n        \"\"\"\n        job_json_start_dir = \"jobs/running\"\n        # check if the job is done or had an error\n        if status_msg_dict[\"status\"] == \"DONE\":\n            # test if the result dict is None\n            if result_dict is None:\n                raise ValueError(\n                    \"The 'result_dict' argument cannot be None if the job is done.\"\n                )\n            # let us create the result json file\n            result_json_dir = \"results/\" + backend_name\n            self.upload(result_dict, result_json_dir, job_id)\n\n            # now move the job out of the running jobs into the finished jobs\n            job_finished_json_dir = \"jobs/finished/\" + backend_name\n            self.move_file(job_json_start_dir, job_finished_json_dir, job_id)\n\n        elif status_msg_dict[\"status\"] == \"ERROR\":\n            # because there was an error, we move the job to the deleted jobs\n            deleted_json_dir = \"jobs/deleted\"\n            self.move_file(job_json_start_dir, deleted_json_dir, job_id)\n\n        # and create the status json file\n        status_json_dir = \"status/\" + backend_name\n        self.update_file(status_msg_dict, status_json_dir, job_id)\n\n    def get_file_queue(self, storage_path: str) -&gt; list[str]:\n        \"\"\"\n        Get a list of files\n\n        Args:\n            storage_path: Where are we looking for the files.\n\n        Returns:\n            A list of files that was found.\n        \"\"\"\n        # get a list of files in the folder\n        full_path = self.base_path + \"/\" + storage_path\n        return os.listdir(full_path)\n\n    def get_next_job_in_queue(self, backend_name: str) -&gt; dict:\n        \"\"\"\n        A function that obtains the next job in the queue.\n\n        Args:\n            backend_name: The name of the backend\n\n        Returns:\n            the path towards the job\n        \"\"\"\n        queue_dir = \"jobs/queued/\" + backend_name\n        job_dict = {\"job_id\": 0, \"job_json_path\": \"None\"}\n        job_list = self.get_file_queue(queue_dir)\n        # if there is a job, we should move it\n        if job_list:\n            job_json_name = job_list[0]\n            job_id = job_json_name[:-5]\n            job_dict[\"job_id\"] = job_id\n\n            # and move the file into the right directory\n            self.move_file(queue_dir, \"jobs/running\", job_id)\n            job_dict[\"job_json_path\"] = \"jobs/running\"\n        return job_dict\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.LocalProvider.__init__","title":"<code>__init__(login_dict)</code>","text":"<p>Set up the neccessary keys and create the client through which all the connections will run.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def __init__(self, login_dict: LocalLoginInformation) -&gt; None:\n    \"\"\"\n    Set up the neccessary keys and create the client through which all the connections will run.\n    \"\"\"\n    self.base_path = login_dict.base_path\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.LocalProvider.delete_file","title":"<code>delete_file(storage_path, job_id)</code>","text":"<p>Delete the file from the storage</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>the path where the file is currently stored, but excluding the file name</p> required <code>job_id</code> <code>str</code> <p>the name of the file</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def delete_file(self, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Delete the file from the storage\n\n    Args:\n        storage_path: the path where the file is currently stored, but excluding the file name\n        job_id: the name of the file\n\n    Returns:\n        None\n    \"\"\"\n    storage_path = storage_path.strip(\"/\")\n    source_file = self.base_path + \"/\" + storage_path + \"/\" + job_id + \".json\"\n    os.remove(source_file)\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.LocalProvider.get_file_content","title":"<code>get_file_content(storage_path, job_id)</code>","text":"<p>Get the file content from the storage</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_file_content(self, storage_path: str, job_id: str) -&gt; dict:\n    \"\"\"\n    Get the file content from the storage\n    \"\"\"\n    # strip trailing and leading slashes from the storage_path\n    storage_path = storage_path.strip(\"/\")\n\n    # create the full path\n    full_json_path = self.base_path + \"/\" + storage_path + \"/\" + job_id + \".json\"\n\n    with open(full_json_path, \"r\", encoding=\"utf-8\") as json_file:\n        loaded_data_dict = json.load(json_file)\n    return loaded_data_dict\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.LocalProvider.get_file_queue","title":"<code>get_file_queue(storage_path)</code>","text":"<p>Get a list of files</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>Where are we looking for the files.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of files that was found.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_file_queue(self, storage_path: str) -&gt; list[str]:\n    \"\"\"\n    Get a list of files\n\n    Args:\n        storage_path: Where are we looking for the files.\n\n    Returns:\n        A list of files that was found.\n    \"\"\"\n    # get a list of files in the folder\n    full_path = self.base_path + \"/\" + storage_path\n    return os.listdir(full_path)\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.LocalProvider.get_job_content","title":"<code>get_job_content(storage_path, job_id)</code>","text":"<p>Get the content of the job from the storage. This is a wrapper around get_file_content and and handles the different ways of identifiying the job.</p> <p>storage_path: the path towards the file, excluding the filename / id job_id: the id of the file we are about to look up</p> <p>Returns:</p> Type Description <code>dict</code> <p>The content of the job</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_job_content(self, storage_path: str, job_id: str) -&gt; dict:\n    \"\"\"\n    Get the content of the job from the storage. This is a wrapper around get_file_content\n    and and handles the different ways of identifiying the job.\n\n    storage_path: the path towards the file, excluding the filename / id\n    job_id: the id of the file we are about to look up\n\n    Returns:\n        The content of the job\n    \"\"\"\n    job_dict = self.get_file_content(storage_path=storage_path, job_id=job_id)\n    return job_dict\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.LocalProvider.get_next_job_in_queue","title":"<code>get_next_job_in_queue(backend_name)</code>","text":"<p>A function that obtains the next job in the queue.</p> <p>Parameters:</p> Name Type Description Default <code>backend_name</code> <code>str</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>dict</code> <p>the path towards the job</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_next_job_in_queue(self, backend_name: str) -&gt; dict:\n    \"\"\"\n    A function that obtains the next job in the queue.\n\n    Args:\n        backend_name: The name of the backend\n\n    Returns:\n        the path towards the job\n    \"\"\"\n    queue_dir = \"jobs/queued/\" + backend_name\n    job_dict = {\"job_id\": 0, \"job_json_path\": \"None\"}\n    job_list = self.get_file_queue(queue_dir)\n    # if there is a job, we should move it\n    if job_list:\n        job_json_name = job_list[0]\n        job_id = job_json_name[:-5]\n        job_dict[\"job_id\"] = job_id\n\n        # and move the file into the right directory\n        self.move_file(queue_dir, \"jobs/running\", job_id)\n        job_dict[\"job_json_path\"] = \"jobs/running\"\n    return job_dict\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.LocalProvider.move_file","title":"<code>move_file(start_path, final_path, job_id)</code>","text":"<p>Move the file from <code>start_path</code> to <code>final_path</code></p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def move_file(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Move the file from `start_path` to `final_path`\n    \"\"\"\n    start_path = start_path.strip(\"/\")\n\n    source_file = self.base_path + \"/\" + start_path + \"/\" + job_id + \".json\"\n    final_path = self.base_path + \"/\" + final_path + \"/\"\n    if not os.path.exists(final_path):\n        os.makedirs(final_path)\n\n    # Move the file\n    shutil.move(source_file, final_path)\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.LocalProvider.update_file","title":"<code>update_file(content_dict, storage_path, job_id)</code>","text":"<p>Update the file content.</p> <p>Parameters:</p> Name Type Description Default <code>content_dict</code> <code>dict</code> <p>The dictionary containing the new content of the file</p> required <code>storage_path</code> <code>str</code> <p>The path to the file</p> required <code>job_id</code> <code>str</code> <p>The id of the job</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def update_file(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Update the file content.\n\n    Args:\n        content_dict: The dictionary containing the new content of the file\n        storage_path: The path to the file\n        job_id: The id of the job\n\n    Returns:\n        None\n    \"\"\"\n    # strip trailing and leading slashes from the storage_path\n    storage_path = storage_path.strip(\"/\")\n\n    # json folder\n    folder_path = self.base_path + \"/\" + storage_path\n\n    # create the full path\n    full_json_path = folder_path + \"/\" + job_id + \".json\"\n\n    # does the file already exist ?\n    if not os.path.exists(full_json_path):\n        raise FileNotFoundError(\n            f\"The file {full_json_path} does not exist and cannot be updated.\"\n        )\n    with open(full_json_path, \"w\", encoding=\"utf-8\") as json_file:\n        json.dump(content_dict, json_file)\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.LocalProvider.update_in_database","title":"<code>update_in_database(result_dict, status_msg_dict, job_id, backend_name)</code>","text":"<p>Upload the status and result to the <code>StorageProvider</code>.</p> <p>Parameters:</p> Name Type Description Default <code>result_dict</code> <code>ResultDict</code> <p>the dictionary containing the result of the job</p> required <code>status_msg_dict</code> <code>dict</code> <p>the dictionary containing the status message of the job</p> required <code>job_id</code> <code>str</code> <p>the name of the job</p> required <code>backend_name</code> <code>str</code> <p>the name of the backend</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def update_in_database(\n    self,\n    result_dict: ResultDict,\n    status_msg_dict: dict,\n    job_id: str,\n    backend_name: str,\n) -&gt; None:\n    \"\"\"\n    Upload the status and result to the `StorageProvider`.\n\n    Args:\n        result_dict: the dictionary containing the result of the job\n        status_msg_dict: the dictionary containing the status message of the job\n        job_id: the name of the job\n        backend_name: the name of the backend\n\n    Returns:\n        None\n    \"\"\"\n    job_json_start_dir = \"jobs/running\"\n    # check if the job is done or had an error\n    if status_msg_dict[\"status\"] == \"DONE\":\n        # test if the result dict is None\n        if result_dict is None:\n            raise ValueError(\n                \"The 'result_dict' argument cannot be None if the job is done.\"\n            )\n        # let us create the result json file\n        result_json_dir = \"results/\" + backend_name\n        self.upload(result_dict, result_json_dir, job_id)\n\n        # now move the job out of the running jobs into the finished jobs\n        job_finished_json_dir = \"jobs/finished/\" + backend_name\n        self.move_file(job_json_start_dir, job_finished_json_dir, job_id)\n\n    elif status_msg_dict[\"status\"] == \"ERROR\":\n        # because there was an error, we move the job to the deleted jobs\n        deleted_json_dir = \"jobs/deleted\"\n        self.move_file(job_json_start_dir, deleted_json_dir, job_id)\n\n    # and create the status json file\n    status_json_dir = \"status/\" + backend_name\n    self.update_file(status_msg_dict, status_json_dir, job_id)\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.LocalProvider.upload","title":"<code>upload(content_dict, storage_path, job_id)</code>","text":"<p>Upload the file to the storage</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def upload(self, content_dict: Mapping, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Upload the file to the storage\n    \"\"\"\n    # strip trailing and leading slashes from the storage_path\n    storage_path = storage_path.strip(\"/\")\n\n    # json folder\n    folder_path = self.base_path + \"/\" + storage_path\n    if not os.path.exists(folder_path):\n        os.makedirs(folder_path)\n\n    # create the full path\n    full_json_path = folder_path + \"/\" + job_id + \".json\"\n\n    with open(full_json_path, \"w\", encoding=\"utf-8\") as json_file:\n        json.dump(content_dict, json_file)\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.LocalProvider.upload_config","title":"<code>upload_config(config_dict, backend_name)</code>","text":"<p>The function that uploads the spooler configuration to the storage.</p> <p>Parameters:</p> Name Type Description Default <code>config_dict</code> <code>dict</code> <p>The dictionary containing the configuration</p> required <code>backend_name</code> <code>str</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def upload_config(self, config_dict: dict, backend_name: str) -&gt; None:\n    \"\"\"\n    The function that uploads the spooler configuration to the storage.\n\n    Args:\n        config_dict: The dictionary containing the configuration\n        backend_name (str): The name of the backend\n\n    Returns:\n        None\n    \"\"\"\n    # path of the configs\n    config_path = self.base_path + \"/backends/configs\"\n    # test if the config path already exists. If it does not, create it\n    if not os.path.exists(config_path):\n        os.makedirs(config_path)\n\n    full_json_path = config_path + \"/\" + backend_name + \".json\"\n    with open(full_json_path, \"w\", encoding=\"utf-8\") as json_file:\n        json.dump(config_dict, json_file)\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.MongodbProvider","title":"<code>MongodbProvider</code>","text":"<p>             Bases: <code>StorageProvider</code></p> <p>The access to the mongodb</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>class MongodbProvider(StorageProvider):\n    \"\"\"\n    The access to the mongodb\n    \"\"\"\n\n    def __init__(self, login_dict: MongodbLoginInformation) -&gt; None:\n        \"\"\"\n        Set up the neccessary keys and create the client through which all the connections will run.\n        \"\"\"\n        mongodb_username = login_dict.mongodb_username\n        mongodb_password = login_dict.mongodb_password\n        mongodb_database_url = login_dict.mongodb_database_url\n\n        uri = f\"mongodb+srv://{mongodb_username}:{mongodb_password}@{mongodb_database_url}\"\n        uri = uri + \"/?retryWrites=true&amp;w=majority\"\n        # Create a new client and connect to the server\n        self.client: MongoClient = MongoClient(uri)\n\n        # Send a ping to confirm a successful connection\n        self.client.admin.command(\"ping\")\n\n    def upload(self, content_dict: Mapping, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Upload the file to the storage\n\n        content_dict: the content that should be uploaded onto the mongodb base\n        storage_path: the access path towards the mongodb collection\n        job_id: the id of the file we are about to create\n        \"\"\"\n        storage_splitted = storage_path.split(\"/\")\n\n        # get the database on which we work\n        database = self.client[storage_splitted[0]]\n\n        # get the collection on which we work\n        collection_name = \".\".join(storage_splitted[1:])\n        collection = database[collection_name]\n\n        content_dict[\"_id\"] = ObjectId(job_id)  # type: ignore\n        collection.insert_one(content_dict)\n\n    def get_file_content(self, storage_path: str, job_id: str) -&gt; dict:\n        \"\"\"\n        Get the file content from the storage\n\n        storage_path: the path towards the file, excluding the filename / id\n        job_id: the id of the file we are about to look up\n        \"\"\"\n        document_to_find = {\"_id\": ObjectId(job_id)}\n\n        # get the database on which we work\n        database = self.client[storage_path.split(\"/\")[0]]\n\n        # get the collection on which we work\n        collection_name = \".\".join(storage_path.split(\"/\")[1:])\n        collection = database[collection_name]\n\n        result_found = collection.find_one(document_to_find)\n\n        if not result_found:\n            return {}\n        return result_found\n\n    def get_job_content(self, storage_path: str, job_id: str) -&gt; dict:\n        \"\"\"\n        Get the content of the job from the storage. This is a wrapper around get_file_content\n        and and handles the different ways of identifiying the job.\n\n        storage_path: the path towards the file, excluding the filename / id\n        job_id: the id of the file we are about to look up\n\n        Returns:\n\n        \"\"\"\n        job_dict = self.get_file_content(storage_path=storage_path, job_id=job_id)\n        job_dict.pop(\"_id\")\n        return job_dict\n\n    def update_file(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Update the file content.\n\n        Args:\n            content_dict: The dictionary containing the new content of the file\n            storage_path: The path to the file\n            job_id: The id of the job\n\n        Returns:\n            None\n        \"\"\"\n        # get the database on which we work\n        database = self.client[storage_path.split(\"/\")[0]]\n\n        # get the collection on which we work\n        collection_name = \".\".join(storage_path.split(\"/\")[1:])\n        collection = database[collection_name]\n\n        filter_dict = {\"_id\": ObjectId(job_id)}\n\n        newvalues = {\"$set\": content_dict}\n        collection.update_one(filter_dict, newvalues)\n\n    def move_file(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Move the file from start_path to final_path\n\n        start_path: the path where the file is currently stored, but excluding the file name\n        final_path: the path where the file should be stored, but excluding the file name\n        job_id: the name of the file. Is a json file\n\n        Returns:\n            None\n        \"\"\"\n        # get the database on which we work\n        database = self.client[start_path.split(\"/\")[0]]\n\n        # get the collection on which we work\n        collection_name = \".\".join(start_path.split(\"/\")[1:])\n        collection = database[collection_name]\n\n        document_to_find = {\"_id\": ObjectId(job_id)}\n        result_found = collection.find_one(document_to_find)\n\n        # delete the old file\n        collection.delete_one(document_to_find)\n\n        # add the document to the new collection\n        database = self.client[final_path.split(\"/\")[0]]\n        collection_name = \".\".join(final_path.split(\"/\")[1:])\n        collection = database[collection_name]\n        collection.insert_one(result_found)\n\n    def delete_file(self, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Remove the file from the mongodb database\n\n        Args:\n            storage_path: the path where the file is currently stored, but excluding the file name\n            job_id: the name of the file\n\n        Returns:\n            None\n        \"\"\"\n        # get the database on which we work\n        database = self.client[storage_path.split(\"/\")[0]]\n\n        # get the collection on which we work\n        collection_name = \".\".join(storage_path.split(\"/\")[1:])\n        collection = database[collection_name]\n\n        document_to_find = {\"_id\": ObjectId(job_id)}\n        collection.delete_one(document_to_find)\n\n    def upload_config(self, config_dict: dict, backend_name: str) -&gt; None:\n        \"\"\"\n        The function that uploads the spooler configuration to the storage.\n\n        Args:\n            config_dict: The dictionary containing the configuration\n            backend_name (str): The name of the backend\n\n        Returns:\n            None\n        \"\"\"\n        config_path = \"backends/configs\"\n\n        # first we have to check if the device already exists in the database\n\n        document_to_find = {\"display_name\": backend_name}\n\n        # get the database on which we work\n        database = self.client[\"backends\"]\n\n        # get the collection on which we work\n        collection = database[\"configs\"]\n\n        result_found = collection.find_one(document_to_find)\n        config_dict[\"display_name\"] = backend_name\n        if result_found:\n            # update the file\n            self.update_file(\n                content_dict=config_dict,\n                storage_path=config_path,\n                job_id=result_found[\"_id\"],\n            )\n            return\n\n        # if the device does not exist, we have to create it\n\n        config_id = uuid.uuid4().hex[:24]\n        self.upload(config_dict, config_path, config_id)\n\n    def update_in_database(\n        self,\n        result_dict: ResultDict | None,\n        status_msg_dict: dict,\n        job_id: str,\n        backend_name: str,\n    ) -&gt; None:\n        \"\"\"\n        Upload the status and result to the `StorageProvider`.\n\n        The function checks if the reported status of the job has changed to DONE. If so, it will create\n        a result json file and move the job json file to the finished folder. It will also update the\n        status json file.\n\n        Args:\n            result_dict: the dictionary containing the result of the job\n            status_msg_dict: the dictionary containing the status message of the job\n            job_id: the name of the job\n            backend_name: the name of the backend\n\n        Returns:\n            None\n\n        Raises:\n\n        \"\"\"\n\n        job_json_start_dir = \"jobs/running\"\n        # check if the job is done or had an error\n        if status_msg_dict[\"status\"] == \"DONE\":\n            # test if the result dict is None\n            if result_dict is None:\n                raise ValueError(\n                    \"The 'result_dict' argument cannot be None if the job is done.\"\n                )\n            # let us create the result json file\n            result_json_dir = \"results/\" + backend_name\n            self.upload(result_dict, result_json_dir, job_id)\n\n            # now move the job out of the running jobs into the finished jobs\n            job_finished_json_dir = \"jobs/finished/\" + backend_name\n            self.move_file(job_json_start_dir, job_finished_json_dir, job_id)\n\n        elif status_msg_dict[\"status\"] == \"ERROR\":\n            # because there was an error, we move the job to the deleted jobs\n            deleted_json_dir = \"jobs/deleted\"\n            self.move_file(job_json_start_dir, deleted_json_dir, job_id)\n\n        # TODO: most likely we should raise an error if the status of the job is not DONE or ERROR\n\n        # and create the status json file\n        status_json_dir = \"status/\" + backend_name\n        self.update_file(status_msg_dict, status_json_dir, job_id)\n\n    def get_file_queue(self, storage_path: str) -&gt; list[str]:\n        \"\"\"\n        Get a list of documents in the collection of all the queued jobs.\n\n        Args:\n            storage_path: Where are we looking for the files.\n\n        Returns:\n            A list of files that was found.\n        \"\"\"\n        # strip trailing and leading slashes from the paths\n        storage_path = storage_path.strip(\"/\")\n\n        # get the database on which we work\n        database = self.client[storage_path.split(\"/\")[0]]\n\n        # get the collection on which we work\n        collection_name = \".\".join(storage_path.split(\"/\")[1:])\n        collection = database[collection_name]\n\n        # now get the id of all the documents in the collection\n        results = collection.find({}, {\"_id\": 1})\n        file_list = []\n        for result in results:\n            file_list.append(str(result[\"_id\"]))\n        return file_list\n\n    def get_next_job_in_queue(self, backend_name: str) -&gt; dict:\n        \"\"\"\n        A function that obtains the next job in the queue. It looks in the queued folder and moves the\n        first job to the running folder.\n\n        Args:\n            backend_name (str): The name of the backend\n\n        Returns:\n            the path towards the job\n        \"\"\"\n\n        queue_dir = \"jobs/queued/\" + backend_name\n        job_dict = {\"job_id\": 0, \"job_json_path\": \"None\"}\n        job_list = self.get_file_queue(queue_dir)\n        # if there is a job, we should move it\n        if job_list:\n            job_id = job_list[0]\n            job_dict[\"job_id\"] = job_id\n\n            # and move the file into the right directory\n            self.move_file(queue_dir, \"jobs/running\", job_id)\n            job_dict[\"job_json_path\"] = \"jobs/running\"\n        return job_dict\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.MongodbProvider.__init__","title":"<code>__init__(login_dict)</code>","text":"<p>Set up the neccessary keys and create the client through which all the connections will run.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def __init__(self, login_dict: MongodbLoginInformation) -&gt; None:\n    \"\"\"\n    Set up the neccessary keys and create the client through which all the connections will run.\n    \"\"\"\n    mongodb_username = login_dict.mongodb_username\n    mongodb_password = login_dict.mongodb_password\n    mongodb_database_url = login_dict.mongodb_database_url\n\n    uri = f\"mongodb+srv://{mongodb_username}:{mongodb_password}@{mongodb_database_url}\"\n    uri = uri + \"/?retryWrites=true&amp;w=majority\"\n    # Create a new client and connect to the server\n    self.client: MongoClient = MongoClient(uri)\n\n    # Send a ping to confirm a successful connection\n    self.client.admin.command(\"ping\")\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.MongodbProvider.delete_file","title":"<code>delete_file(storage_path, job_id)</code>","text":"<p>Remove the file from the mongodb database</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>the path where the file is currently stored, but excluding the file name</p> required <code>job_id</code> <code>str</code> <p>the name of the file</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def delete_file(self, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Remove the file from the mongodb database\n\n    Args:\n        storage_path: the path where the file is currently stored, but excluding the file name\n        job_id: the name of the file\n\n    Returns:\n        None\n    \"\"\"\n    # get the database on which we work\n    database = self.client[storage_path.split(\"/\")[0]]\n\n    # get the collection on which we work\n    collection_name = \".\".join(storage_path.split(\"/\")[1:])\n    collection = database[collection_name]\n\n    document_to_find = {\"_id\": ObjectId(job_id)}\n    collection.delete_one(document_to_find)\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.MongodbProvider.get_file_content","title":"<code>get_file_content(storage_path, job_id)</code>","text":"<p>Get the file content from the storage</p> <p>storage_path: the path towards the file, excluding the filename / id job_id: the id of the file we are about to look up</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_file_content(self, storage_path: str, job_id: str) -&gt; dict:\n    \"\"\"\n    Get the file content from the storage\n\n    storage_path: the path towards the file, excluding the filename / id\n    job_id: the id of the file we are about to look up\n    \"\"\"\n    document_to_find = {\"_id\": ObjectId(job_id)}\n\n    # get the database on which we work\n    database = self.client[storage_path.split(\"/\")[0]]\n\n    # get the collection on which we work\n    collection_name = \".\".join(storage_path.split(\"/\")[1:])\n    collection = database[collection_name]\n\n    result_found = collection.find_one(document_to_find)\n\n    if not result_found:\n        return {}\n    return result_found\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.MongodbProvider.get_file_queue","title":"<code>get_file_queue(storage_path)</code>","text":"<p>Get a list of documents in the collection of all the queued jobs.</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>Where are we looking for the files.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of files that was found.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_file_queue(self, storage_path: str) -&gt; list[str]:\n    \"\"\"\n    Get a list of documents in the collection of all the queued jobs.\n\n    Args:\n        storage_path: Where are we looking for the files.\n\n    Returns:\n        A list of files that was found.\n    \"\"\"\n    # strip trailing and leading slashes from the paths\n    storage_path = storage_path.strip(\"/\")\n\n    # get the database on which we work\n    database = self.client[storage_path.split(\"/\")[0]]\n\n    # get the collection on which we work\n    collection_name = \".\".join(storage_path.split(\"/\")[1:])\n    collection = database[collection_name]\n\n    # now get the id of all the documents in the collection\n    results = collection.find({}, {\"_id\": 1})\n    file_list = []\n    for result in results:\n        file_list.append(str(result[\"_id\"]))\n    return file_list\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.MongodbProvider.get_job_content","title":"<code>get_job_content(storage_path, job_id)</code>","text":"<p>Get the content of the job from the storage. This is a wrapper around get_file_content and and handles the different ways of identifiying the job.</p> <p>storage_path: the path towards the file, excluding the filename / id job_id: the id of the file we are about to look up</p> <p>Returns:</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_job_content(self, storage_path: str, job_id: str) -&gt; dict:\n    \"\"\"\n    Get the content of the job from the storage. This is a wrapper around get_file_content\n    and and handles the different ways of identifiying the job.\n\n    storage_path: the path towards the file, excluding the filename / id\n    job_id: the id of the file we are about to look up\n\n    Returns:\n\n    \"\"\"\n    job_dict = self.get_file_content(storage_path=storage_path, job_id=job_id)\n    job_dict.pop(\"_id\")\n    return job_dict\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.MongodbProvider.get_next_job_in_queue","title":"<code>get_next_job_in_queue(backend_name)</code>","text":"<p>A function that obtains the next job in the queue. It looks in the queued folder and moves the first job to the running folder.</p> <p>Parameters:</p> Name Type Description Default <code>backend_name</code> <code>str</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>dict</code> <p>the path towards the job</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def get_next_job_in_queue(self, backend_name: str) -&gt; dict:\n    \"\"\"\n    A function that obtains the next job in the queue. It looks in the queued folder and moves the\n    first job to the running folder.\n\n    Args:\n        backend_name (str): The name of the backend\n\n    Returns:\n        the path towards the job\n    \"\"\"\n\n    queue_dir = \"jobs/queued/\" + backend_name\n    job_dict = {\"job_id\": 0, \"job_json_path\": \"None\"}\n    job_list = self.get_file_queue(queue_dir)\n    # if there is a job, we should move it\n    if job_list:\n        job_id = job_list[0]\n        job_dict[\"job_id\"] = job_id\n\n        # and move the file into the right directory\n        self.move_file(queue_dir, \"jobs/running\", job_id)\n        job_dict[\"job_json_path\"] = \"jobs/running\"\n    return job_dict\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.MongodbProvider.move_file","title":"<code>move_file(start_path, final_path, job_id)</code>","text":"<p>Move the file from start_path to final_path</p> <p>start_path: the path where the file is currently stored, but excluding the file name final_path: the path where the file should be stored, but excluding the file name job_id: the name of the file. Is a json file</p> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def move_file(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Move the file from start_path to final_path\n\n    start_path: the path where the file is currently stored, but excluding the file name\n    final_path: the path where the file should be stored, but excluding the file name\n    job_id: the name of the file. Is a json file\n\n    Returns:\n        None\n    \"\"\"\n    # get the database on which we work\n    database = self.client[start_path.split(\"/\")[0]]\n\n    # get the collection on which we work\n    collection_name = \".\".join(start_path.split(\"/\")[1:])\n    collection = database[collection_name]\n\n    document_to_find = {\"_id\": ObjectId(job_id)}\n    result_found = collection.find_one(document_to_find)\n\n    # delete the old file\n    collection.delete_one(document_to_find)\n\n    # add the document to the new collection\n    database = self.client[final_path.split(\"/\")[0]]\n    collection_name = \".\".join(final_path.split(\"/\")[1:])\n    collection = database[collection_name]\n    collection.insert_one(result_found)\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.MongodbProvider.update_file","title":"<code>update_file(content_dict, storage_path, job_id)</code>","text":"<p>Update the file content.</p> <p>Parameters:</p> Name Type Description Default <code>content_dict</code> <code>dict</code> <p>The dictionary containing the new content of the file</p> required <code>storage_path</code> <code>str</code> <p>The path to the file</p> required <code>job_id</code> <code>str</code> <p>The id of the job</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def update_file(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Update the file content.\n\n    Args:\n        content_dict: The dictionary containing the new content of the file\n        storage_path: The path to the file\n        job_id: The id of the job\n\n    Returns:\n        None\n    \"\"\"\n    # get the database on which we work\n    database = self.client[storage_path.split(\"/\")[0]]\n\n    # get the collection on which we work\n    collection_name = \".\".join(storage_path.split(\"/\")[1:])\n    collection = database[collection_name]\n\n    filter_dict = {\"_id\": ObjectId(job_id)}\n\n    newvalues = {\"$set\": content_dict}\n    collection.update_one(filter_dict, newvalues)\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.MongodbProvider.update_in_database","title":"<code>update_in_database(result_dict, status_msg_dict, job_id, backend_name)</code>","text":"<p>Upload the status and result to the <code>StorageProvider</code>.</p> <p>The function checks if the reported status of the job has changed to DONE. If so, it will create a result json file and move the job json file to the finished folder. It will also update the status json file.</p> <p>Parameters:</p> Name Type Description Default <code>result_dict</code> <code>ResultDict | None</code> <p>the dictionary containing the result of the job</p> required <code>status_msg_dict</code> <code>dict</code> <p>the dictionary containing the status message of the job</p> required <code>job_id</code> <code>str</code> <p>the name of the job</p> required <code>backend_name</code> <code>str</code> <p>the name of the backend</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> <p>Raises:</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def update_in_database(\n    self,\n    result_dict: ResultDict | None,\n    status_msg_dict: dict,\n    job_id: str,\n    backend_name: str,\n) -&gt; None:\n    \"\"\"\n    Upload the status and result to the `StorageProvider`.\n\n    The function checks if the reported status of the job has changed to DONE. If so, it will create\n    a result json file and move the job json file to the finished folder. It will also update the\n    status json file.\n\n    Args:\n        result_dict: the dictionary containing the result of the job\n        status_msg_dict: the dictionary containing the status message of the job\n        job_id: the name of the job\n        backend_name: the name of the backend\n\n    Returns:\n        None\n\n    Raises:\n\n    \"\"\"\n\n    job_json_start_dir = \"jobs/running\"\n    # check if the job is done or had an error\n    if status_msg_dict[\"status\"] == \"DONE\":\n        # test if the result dict is None\n        if result_dict is None:\n            raise ValueError(\n                \"The 'result_dict' argument cannot be None if the job is done.\"\n            )\n        # let us create the result json file\n        result_json_dir = \"results/\" + backend_name\n        self.upload(result_dict, result_json_dir, job_id)\n\n        # now move the job out of the running jobs into the finished jobs\n        job_finished_json_dir = \"jobs/finished/\" + backend_name\n        self.move_file(job_json_start_dir, job_finished_json_dir, job_id)\n\n    elif status_msg_dict[\"status\"] == \"ERROR\":\n        # because there was an error, we move the job to the deleted jobs\n        deleted_json_dir = \"jobs/deleted\"\n        self.move_file(job_json_start_dir, deleted_json_dir, job_id)\n\n    # TODO: most likely we should raise an error if the status of the job is not DONE or ERROR\n\n    # and create the status json file\n    status_json_dir = \"status/\" + backend_name\n    self.update_file(status_msg_dict, status_json_dir, job_id)\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.MongodbProvider.upload","title":"<code>upload(content_dict, storage_path, job_id)</code>","text":"<p>Upload the file to the storage</p> <p>content_dict: the content that should be uploaded onto the mongodb base storage_path: the access path towards the mongodb collection job_id: the id of the file we are about to create</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def upload(self, content_dict: Mapping, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Upload the file to the storage\n\n    content_dict: the content that should be uploaded onto the mongodb base\n    storage_path: the access path towards the mongodb collection\n    job_id: the id of the file we are about to create\n    \"\"\"\n    storage_splitted = storage_path.split(\"/\")\n\n    # get the database on which we work\n    database = self.client[storage_splitted[0]]\n\n    # get the collection on which we work\n    collection_name = \".\".join(storage_splitted[1:])\n    collection = database[collection_name]\n\n    content_dict[\"_id\"] = ObjectId(job_id)  # type: ignore\n    collection.insert_one(content_dict)\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.MongodbProvider.upload_config","title":"<code>upload_config(config_dict, backend_name)</code>","text":"<p>The function that uploads the spooler configuration to the storage.</p> <p>Parameters:</p> Name Type Description Default <code>config_dict</code> <code>dict</code> <p>The dictionary containing the configuration</p> required <code>backend_name</code> <code>str</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>def upload_config(self, config_dict: dict, backend_name: str) -&gt; None:\n    \"\"\"\n    The function that uploads the spooler configuration to the storage.\n\n    Args:\n        config_dict: The dictionary containing the configuration\n        backend_name (str): The name of the backend\n\n    Returns:\n        None\n    \"\"\"\n    config_path = \"backends/configs\"\n\n    # first we have to check if the device already exists in the database\n\n    document_to_find = {\"display_name\": backend_name}\n\n    # get the database on which we work\n    database = self.client[\"backends\"]\n\n    # get the collection on which we work\n    collection = database[\"configs\"]\n\n    result_found = collection.find_one(document_to_find)\n    config_dict[\"display_name\"] = backend_name\n    if result_found:\n        # update the file\n        self.update_file(\n            content_dict=config_dict,\n            storage_path=config_path,\n            job_id=result_found[\"_id\"],\n        )\n        return\n\n    # if the device does not exist, we have to create it\n\n    config_id = uuid.uuid4().hex[:24]\n    self.upload(config_dict, config_path, config_id)\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.StorageProvider","title":"<code>StorageProvider</code>","text":"<p>             Bases: <code>ABC</code></p> <p>The template for accessing any storage providers like dropbox, mongodb, amazon S3 etc.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>class StorageProvider(ABC):\n    \"\"\"\n    The template for accessing any storage providers like dropbox, mongodb, amazon S3 etc.\n    \"\"\"\n\n    @abstractmethod\n    def upload(self, content_dict: Mapping, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Upload the file to the storage\n        \"\"\"\n\n    @abstractmethod\n    def get_file_content(self, storage_path: str, job_id: str) -&gt; dict:\n        \"\"\"\n        Get the file content from the storage\n        \"\"\"\n\n    @abstractmethod\n    def get_job_content(self, storage_path: str, job_id: str) -&gt; dict:\n        \"\"\"\n        Get the content of the job from the storage. This is a wrapper around get_file_content\n        and and handles the different ways of identifiying the job.\n\n        storage_path: the path towards the file, excluding the filename / id\n        job_id: the id of the file we are about to look up\n\n        Returns:\n            The content of the job\n        \"\"\"\n\n    @abstractmethod\n    def update_file(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Update the file content.\n\n        Args:\n            content_dict: The dictionary containing the new content of the file\n            storage_path: The path to the file\n            job_id: The id of the job\n\n        Returns:\n            None\n        \"\"\"\n\n    @abstractmethod\n    def move_file(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Move the file from `start_path` to `final_path`\n        \"\"\"\n\n    @abstractmethod\n    def delete_file(self, storage_path: str, job_id: str) -&gt; None:\n        \"\"\"\n        Delete the file from the storage\n        \"\"\"\n\n    @abstractmethod\n    def upload_config(self, config_dict: dict, backend_name: str) -&gt; None:\n        \"\"\"\n        The function that uploads the spooler configuration to the storage.\n\n        Args:\n            config_dict: The dictionary containing the configuration\n            backend_name (str): The name of the backend\n\n        Returns:\n            None\n        \"\"\"\n\n    @abstractmethod\n    def update_in_database(\n        self,\n        result_dict: ResultDict,\n        status_msg_dict: dict,\n        job_id: str,\n        backend_name: str,\n    ) -&gt; None:\n        \"\"\"\n        Upload the status and result to the `StorageProvider`.\n\n        Args:\n            result_dict: the dictionary containing the result of the job\n            status_msg_dict: the dictionary containing the status message of the job\n            job_id: the name of the job\n            backend_name: the name of the backend\n\n        Returns:\n            None\n        \"\"\"\n\n    @abstractmethod\n    def get_file_queue(self, storage_path: str) -&gt; list[str]:\n        \"\"\"\n        Get a list of files\n\n        Args:\n            storage_path: Where are we looking for the files.\n\n        Returns:\n            A list of files that was found.\n        \"\"\"\n\n    @abstractmethod\n    def get_next_job_in_queue(self, backend_name: str) -&gt; dict:\n        \"\"\"\n        A function that obtains the next job in the queue.\n\n        Args:\n            backend_name (str): The name of the backend\n\n        Returns:\n            the path towards the job\n        \"\"\"\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.StorageProvider.delete_file","title":"<code>delete_file(storage_path, job_id)</code>  <code>abstractmethod</code>","text":"<p>Delete the file from the storage</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@abstractmethod\ndef delete_file(self, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Delete the file from the storage\n    \"\"\"\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.StorageProvider.get_file_content","title":"<code>get_file_content(storage_path, job_id)</code>  <code>abstractmethod</code>","text":"<p>Get the file content from the storage</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@abstractmethod\ndef get_file_content(self, storage_path: str, job_id: str) -&gt; dict:\n    \"\"\"\n    Get the file content from the storage\n    \"\"\"\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.StorageProvider.get_file_queue","title":"<code>get_file_queue(storage_path)</code>  <code>abstractmethod</code>","text":"<p>Get a list of files</p> <p>Parameters:</p> Name Type Description Default <code>storage_path</code> <code>str</code> <p>Where are we looking for the files.</p> required <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of files that was found.</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@abstractmethod\ndef get_file_queue(self, storage_path: str) -&gt; list[str]:\n    \"\"\"\n    Get a list of files\n\n    Args:\n        storage_path: Where are we looking for the files.\n\n    Returns:\n        A list of files that was found.\n    \"\"\"\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.StorageProvider.get_job_content","title":"<code>get_job_content(storage_path, job_id)</code>  <code>abstractmethod</code>","text":"<p>Get the content of the job from the storage. This is a wrapper around get_file_content and and handles the different ways of identifiying the job.</p> <p>storage_path: the path towards the file, excluding the filename / id job_id: the id of the file we are about to look up</p> <p>Returns:</p> Type Description <code>dict</code> <p>The content of the job</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@abstractmethod\ndef get_job_content(self, storage_path: str, job_id: str) -&gt; dict:\n    \"\"\"\n    Get the content of the job from the storage. This is a wrapper around get_file_content\n    and and handles the different ways of identifiying the job.\n\n    storage_path: the path towards the file, excluding the filename / id\n    job_id: the id of the file we are about to look up\n\n    Returns:\n        The content of the job\n    \"\"\"\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.StorageProvider.get_next_job_in_queue","title":"<code>get_next_job_in_queue(backend_name)</code>  <code>abstractmethod</code>","text":"<p>A function that obtains the next job in the queue.</p> <p>Parameters:</p> Name Type Description Default <code>backend_name</code> <code>str</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>dict</code> <p>the path towards the job</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@abstractmethod\ndef get_next_job_in_queue(self, backend_name: str) -&gt; dict:\n    \"\"\"\n    A function that obtains the next job in the queue.\n\n    Args:\n        backend_name (str): The name of the backend\n\n    Returns:\n        the path towards the job\n    \"\"\"\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.StorageProvider.move_file","title":"<code>move_file(start_path, final_path, job_id)</code>  <code>abstractmethod</code>","text":"<p>Move the file from <code>start_path</code> to <code>final_path</code></p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@abstractmethod\ndef move_file(self, start_path: str, final_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Move the file from `start_path` to `final_path`\n    \"\"\"\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.StorageProvider.update_file","title":"<code>update_file(content_dict, storage_path, job_id)</code>  <code>abstractmethod</code>","text":"<p>Update the file content.</p> <p>Parameters:</p> Name Type Description Default <code>content_dict</code> <code>dict</code> <p>The dictionary containing the new content of the file</p> required <code>storage_path</code> <code>str</code> <p>The path to the file</p> required <code>job_id</code> <code>str</code> <p>The id of the job</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@abstractmethod\ndef update_file(self, content_dict: dict, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Update the file content.\n\n    Args:\n        content_dict: The dictionary containing the new content of the file\n        storage_path: The path to the file\n        job_id: The id of the job\n\n    Returns:\n        None\n    \"\"\"\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.StorageProvider.update_in_database","title":"<code>update_in_database(result_dict, status_msg_dict, job_id, backend_name)</code>  <code>abstractmethod</code>","text":"<p>Upload the status and result to the <code>StorageProvider</code>.</p> <p>Parameters:</p> Name Type Description Default <code>result_dict</code> <code>ResultDict</code> <p>the dictionary containing the result of the job</p> required <code>status_msg_dict</code> <code>dict</code> <p>the dictionary containing the status message of the job</p> required <code>job_id</code> <code>str</code> <p>the name of the job</p> required <code>backend_name</code> <code>str</code> <p>the name of the backend</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@abstractmethod\ndef update_in_database(\n    self,\n    result_dict: ResultDict,\n    status_msg_dict: dict,\n    job_id: str,\n    backend_name: str,\n) -&gt; None:\n    \"\"\"\n    Upload the status and result to the `StorageProvider`.\n\n    Args:\n        result_dict: the dictionary containing the result of the job\n        status_msg_dict: the dictionary containing the status message of the job\n        job_id: the name of the job\n        backend_name: the name of the backend\n\n    Returns:\n        None\n    \"\"\"\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.StorageProvider.upload","title":"<code>upload(content_dict, storage_path, job_id)</code>  <code>abstractmethod</code>","text":"<p>Upload the file to the storage</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@abstractmethod\ndef upload(self, content_dict: Mapping, storage_path: str, job_id: str) -&gt; None:\n    \"\"\"\n    Upload the file to the storage\n    \"\"\"\n</code></pre>"},{"location":"utils/#src.sqooler.storage_providers.StorageProvider.upload_config","title":"<code>upload_config(config_dict, backend_name)</code>  <code>abstractmethod</code>","text":"<p>The function that uploads the spooler configuration to the storage.</p> <p>Parameters:</p> Name Type Description Default <code>config_dict</code> <code>dict</code> <p>The dictionary containing the configuration</p> required <code>backend_name</code> <code>str</code> <p>The name of the backend</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>src/sqooler/storage_providers.py</code> <pre><code>@abstractmethod\ndef upload_config(self, config_dict: dict, backend_name: str) -&gt; None:\n    \"\"\"\n    The function that uploads the spooler configuration to the storage.\n\n    Args:\n        config_dict: The dictionary containing the configuration\n        backend_name (str): The name of the backend\n\n    Returns:\n        None\n    \"\"\"\n</code></pre>"},{"location":"utils/#schemes","title":"Schemes","text":"<p>The module that contains common logic for schemes, validation etc. There is no obvious need, why this code should be touch in a new back-end.</p>"},{"location":"utils/#src.sqooler.schemes.DropboxLoginInformation","title":"<code>DropboxLoginInformation</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>The login information for the dropbox</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class DropboxLoginInformation(BaseModel):\n    \"\"\"\n    The login information for the dropbox\n    \"\"\"\n\n    app_key: str\n    app_secret: str\n    refresh_token: str\n</code></pre>"},{"location":"utils/#src.sqooler.schemes.ExperimentDict","title":"<code>ExperimentDict</code>","text":"<p>             Bases: <code>TypedDict</code></p> <p>A class that defines the structure of the experiments.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class ExperimentDict(TypedDict):\n    \"\"\"\n    A class that defines the structure of the experiments.\n    \"\"\"\n\n    header: dict\n    shots: int\n    success: bool\n    data: dict\n</code></pre>"},{"location":"utils/#src.sqooler.schemes.GateInstruction","title":"<code>GateInstruction</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>The basic class for all the gate intructions of a backend. Any gate has to have the following attributes.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class GateInstruction(BaseModel):\n    \"\"\"\n    The basic class for all the gate intructions of a backend.\n    Any gate has to have the following attributes.\n    \"\"\"\n\n    name: str\n    parameters: str\n    description: str\n    coupling_map: list\n    qasm_def: str = \"{}\"\n    is_gate: bool = True\n\n    @classmethod\n    def config_dict(cls) -&gt; dict:\n        \"\"\"\n        Give back the properties of the instruction such as needed for the server.\n        \"\"\"\n        return {\n            \"coupling_map\": cls.model_fields[\"coupling_map\"].default,\n            \"description\": cls.model_fields[\"description\"].default,\n            \"name\": cls.model_fields[\"name\"].default,\n            \"parameters\": [cls.model_fields[\"parameters\"].default],\n            \"qasm_def\": cls.model_fields[\"qasm_def\"].default,\n        }\n</code></pre>"},{"location":"utils/#src.sqooler.schemes.GateInstruction.config_dict","title":"<code>config_dict()</code>  <code>classmethod</code>","text":"<p>Give back the properties of the instruction such as needed for the server.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>@classmethod\ndef config_dict(cls) -&gt; dict:\n    \"\"\"\n    Give back the properties of the instruction such as needed for the server.\n    \"\"\"\n    return {\n        \"coupling_map\": cls.model_fields[\"coupling_map\"].default,\n        \"description\": cls.model_fields[\"description\"].default,\n        \"name\": cls.model_fields[\"name\"].default,\n        \"parameters\": [cls.model_fields[\"parameters\"].default],\n        \"qasm_def\": cls.model_fields[\"qasm_def\"].default,\n    }\n</code></pre>"},{"location":"utils/#src.sqooler.schemes.LocalLoginInformation","title":"<code>LocalLoginInformation</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>The login information for a local storage provider.</p> <p>base_path: The base path of the storage provider on your local file system.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class LocalLoginInformation(BaseModel):\n    \"\"\"\n    The login information for a local storage provider.\n\n    base_path: The base path of the storage provider on your local file system.\n    \"\"\"\n\n    base_path: str\n</code></pre>"},{"location":"utils/#src.sqooler.schemes.MongodbLoginInformation","title":"<code>MongodbLoginInformation</code>","text":"<p>             Bases: <code>BaseModel</code></p> <p>The login information for MongoDB</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class MongodbLoginInformation(BaseModel):\n    \"\"\"\n    The login information for MongoDB\n    \"\"\"\n\n    mongodb_username: str\n    mongodb_password: str\n    mongodb_database_url: str\n</code></pre>"},{"location":"utils/#src.sqooler.schemes.ResultDict","title":"<code>ResultDict</code>","text":"<p>             Bases: <code>TypedDict</code></p> <p>A class that defines the structure of results.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>class ResultDict(TypedDict):\n    \"\"\"\n    A class that defines the structure of results.\n    \"\"\"\n\n    display_name: str\n    backend_version: str\n    job_id: str\n    qobj_id: str | None\n    success: bool\n    status: str\n    header: dict\n    results: list\n    backend_name: NotRequired[str]\n</code></pre>"},{"location":"utils/#src.sqooler.schemes.Spooler","title":"<code>Spooler</code>","text":"<p>The class for the spooler. So it is not just a scheme, but it also contains some common logic. So it should most likely live in another file at some point.</p> <p>Attributes:</p> Name Type Description <code>n_max_wires</code> <p>maximum number of wires for the spooler</p> <code>n_max_shots</code> <p>the maximum number of shots for the spooler</p> <code>ins_schema_dict</code> <p>A dictionary the contains all the allowed instructions for this spooler.</p> <p>Parameters:</p> Name Type Description Default <code>exper_schema</code> <p>Sets the <code>exper_schema</code> attribute of the class</p> required <code>ins_schema_dict</code> <p>Sets the <code>ins_schema_dict</code> attribute of the class</p> required Source code in <code>src/sqooler/schemes.py</code> <pre><code>class Spooler:\n    \"\"\"\n    The class for the spooler. So it is not just a scheme, but it also contains some common logic.\n    So it should most likely live in another file at some point.\n\n    Attributes:\n        n_max_wires: maximum number of wires for the spooler\n        n_max_shots: the maximum number of shots for the spooler\n        ins_schema_dict : A dictionary the contains all the allowed instructions for this spooler.\n\n    Args:\n        exper_schema: Sets the `exper_schema` attribute of the class\n        ins_schema_dict : Sets the `ins_schema_dict` attribute of the class\n    \"\"\"\n\n    def __init__(\n        self,\n        ins_schema_dict: dict,\n        n_wires: int,\n        description: str = \"\",\n        n_max_shots: int = 1000,\n        version: str = \"0.0.1\",\n        cold_atom_type: str = \"spin\",\n        n_max_experiments: int = 15,\n        wire_order: str = \"interleaved\",\n        num_species: int = 1,\n    ):\n        \"\"\"\n        The constructor of the class.\n        \"\"\"\n        self.ins_schema_dict = ins_schema_dict\n        self.n_max_shots = n_max_shots\n        self.n_wires = n_wires\n        self.description = description\n        self.version = version\n        self.cold_atom_type = cold_atom_type\n        self.n_max_experiments = n_max_experiments\n        self.wire_order = wire_order\n        self.num_species = num_species\n        self._display_name: str = \"\"\n\n    def check_experiment(self, exper_dict: dict) -&gt; tuple[str, bool]:\n        \"\"\"\n        Check the validity of the experiment.\n        This has to be implement in each subclass extra.\n\n        Args:\n            exper_dict: The dictionary that contains the logic and should\n                be verified.\n        \"\"\"\n        raise NotImplementedError(\"Subclasses should implement this!\")\n\n    def get_configuration(self) -&gt; dict:\n        \"\"\"\n        Sends back the configuration dictionary of the spooler.\n        \"\"\"\n        gate_list = []\n        for _, ins_obj in self.ins_schema_dict.items():\n            if \"is_gate\" in ins_obj.model_fields:\n                gate_list.append(ins_obj.config_dict())\n        return {\n            \"description\": self.description,\n            \"version\": self.version,\n            \"cold_atom_type\": self.cold_atom_type,\n            \"gates\": gate_list,\n            \"max_experiments\": self.n_max_experiments,\n            \"max_shots\": self.n_max_shots,\n            \"simulator\": True,\n            \"supported_instructions\": list(self.ins_schema_dict.keys()),\n            \"num_wires\": self.n_wires,\n            \"wire_order\": self.wire_order,\n            \"num_species\": self.num_species,\n        }\n\n    def check_instructions(self, ins_list: list) -&gt; tuple[str, bool]:\n        \"\"\"\n        Check all the instruction to make sure that they are valid.\n        \"\"\"\n        err_code = \"\"\n        exp_ok = False\n        for ins in ins_list:\n            try:\n                gate_dict = gate_dict_from_list(ins)\n                self.ins_schema_dict[ins[0]](**gate_dict)\n                exp_ok = True\n            except ValidationError as err:\n                err_code = \"Error in instruction \" + str(err)\n                exp_ok = False\n            if not exp_ok:\n                break\n        return err_code, exp_ok\n\n    def check_dimension(self, json_dict: dict) -&gt; tuple[str, bool]:\n        \"\"\"\n        Make sure that the Hilbert space dimension is not too large.\n\n        It can be implemented in the class that inherits, but it is not necessary.\n        So this is only a placeholder.\n\n        Args:\n            json_dict: the dictonary with the instructions\n\n        Returns:\n            str: the error message\n            bool: is the dimension ok ?\n        \"\"\"\n        # pylint: disable=W0613\n        return \"\", True\n\n    def check_json_dict(self, json_dict: dict) -&gt; tuple[str, bool]:\n        \"\"\"\n        Check if the json file has the appropiate syntax.\n\n        Args:\n            json_dict (dict): the dictonary that we will test.\n\n        Returns:\n            bool: is the expression having the appropiate syntax ?\n        \"\"\"\n        for expr in json_dict:\n            err_code = \"Wrong experiment name or too many experiments\"\n            # Fix this pylint issue whenever you have time, but be careful !\n            # pylint: disable=W0702\n            try:\n                exp_ok = (\n                    expr.startswith(\"experiment_\")\n                    and expr[11:].isdigit()\n                    and (int(expr[11:]) &lt;= self.n_max_experiments)\n                )\n            except:\n                exp_ok = False\n                break\n            if not exp_ok:\n                break\n            # test the structure of the experiment\n            err_code, exp_ok = self.check_experiment(json_dict[expr])\n            if not exp_ok:\n                break\n            # time to check the structure of the instructions\n            ins_list = json_dict[expr][\"instructions\"]\n            err_code, exp_ok = self.check_instructions(ins_list)\n            if not exp_ok:\n                break\n        return err_code.replace(\"\\n\", \"..\"), exp_ok\n\n    @property\n    def display_name(self) -&gt; str:\n        \"\"\"\n        The name of the spooler.\n        \"\"\"\n        return self._display_name\n\n    @display_name.setter\n    def display_name(self, value: str) -&gt; None:\n        if isinstance(value, str):  # Check if the provided value is a string\n            self._display_name = value\n        else:\n            raise ValueError(\"display_name must be a string\")\n\n    @property\n    def gen_circuit(self) -&gt; Callable[[dict], ExperimentDict]:\n        \"\"\"\n        The function that generates the circuit.\n        It can be basically anything that allows the execution of the circuit.\n        \"\"\"\n        return self._gen_circuit\n\n    @gen_circuit.setter\n    def gen_circuit(self, value: Callable[[dict], ExperimentDict]) -&gt; None:\n        if callable(value):  # Check if the provided value is a callable (function)\n            self._gen_circuit = value\n        else:\n            raise ValueError(\"gen_circuit must be a callable function\")\n\n    def add_job(\n        self, json_dict: dict, status_msg_dict: dict\n    ) -&gt; tuple[ResultDict, dict]:\n        \"\"\"\n        The function that translates the json with the instructions into some circuit and executes it.\n        It performs several checks for the job to see if it is properly working.\n        If things are fine the job gets added the list of things that should be executed.\n\n        json_dict: The job dictonary of all the instructions.\n        status_msg_dict: the status dictionary of the job we are treating.\n        \"\"\"\n        job_id = status_msg_dict[\"job_id\"]\n\n        result_dict: ResultDict = {\n            \"display_name\": self.display_name,\n            \"backend_version\": self.version,\n            \"job_id\": job_id,\n            \"qobj_id\": None,\n            \"success\": True,\n            \"status\": \"finished\",\n            \"header\": {},\n            \"results\": [],\n        }\n        err_msg, json_is_fine = self.check_json_dict(json_dict)\n        if json_is_fine:\n            # check_hilbert_space_dimension\n            dim_err_msg, dim_ok = self.check_dimension(json_dict)\n            if dim_ok:\n                for exp in json_dict:\n                    exp_dict = {exp: json_dict[exp]}\n                    # Here we\n                    result_dict[\"results\"].append(self.gen_circuit(exp_dict))\n\n                status_msg_dict[\n                    \"detail\"\n                ] += \"; Passed json sanity check; Compilation done. Shots sent to solver.\"\n                status_msg_dict[\"status\"] = \"DONE\"\n                return result_dict, status_msg_dict\n\n            status_msg_dict[\"detail\"] += (\n                \"; Failed dimensionality test. Too many atoms. File will be deleted. Error message : \"\n                + dim_err_msg\n            )\n            status_msg_dict[\"error_message\"] += (\n                \"; Failed dimensionality test. Too many atoms. File will be deleted. Error message :  \"\n                + dim_err_msg\n            )\n            status_msg_dict[\"status\"] = \"ERROR\"\n            return result_dict, status_msg_dict\n        else:\n            status_msg_dict[\"detail\"] += (\n                \"; Failed json sanity check. File will be deleted. Error message : \"\n                + err_msg\n            )\n            status_msg_dict[\"error_message\"] += (\n                \"; Failed json sanity check. File will be deleted. Error message : \"\n                + err_msg\n            )\n            status_msg_dict[\"status\"] = \"ERROR\"\n        return result_dict, status_msg_dict\n</code></pre>"},{"location":"utils/#src.sqooler.schemes.Spooler.display_name","title":"<code>display_name: str</code>  <code>property</code> <code>writable</code>","text":"<p>The name of the spooler.</p>"},{"location":"utils/#src.sqooler.schemes.Spooler.gen_circuit","title":"<code>gen_circuit: Callable[[dict], ExperimentDict]</code>  <code>property</code> <code>writable</code>","text":"<p>The function that generates the circuit. It can be basically anything that allows the execution of the circuit.</p>"},{"location":"utils/#src.sqooler.schemes.Spooler.__init__","title":"<code>__init__(ins_schema_dict, n_wires, description='', n_max_shots=1000, version='0.0.1', cold_atom_type='spin', n_max_experiments=15, wire_order='interleaved', num_species=1)</code>","text":"<p>The constructor of the class.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>def __init__(\n    self,\n    ins_schema_dict: dict,\n    n_wires: int,\n    description: str = \"\",\n    n_max_shots: int = 1000,\n    version: str = \"0.0.1\",\n    cold_atom_type: str = \"spin\",\n    n_max_experiments: int = 15,\n    wire_order: str = \"interleaved\",\n    num_species: int = 1,\n):\n    \"\"\"\n    The constructor of the class.\n    \"\"\"\n    self.ins_schema_dict = ins_schema_dict\n    self.n_max_shots = n_max_shots\n    self.n_wires = n_wires\n    self.description = description\n    self.version = version\n    self.cold_atom_type = cold_atom_type\n    self.n_max_experiments = n_max_experiments\n    self.wire_order = wire_order\n    self.num_species = num_species\n    self._display_name: str = \"\"\n</code></pre>"},{"location":"utils/#src.sqooler.schemes.Spooler.add_job","title":"<code>add_job(json_dict, status_msg_dict)</code>","text":"<p>The function that translates the json with the instructions into some circuit and executes it. It performs several checks for the job to see if it is properly working. If things are fine the job gets added the list of things that should be executed.</p> <p>json_dict: The job dictonary of all the instructions. status_msg_dict: the status dictionary of the job we are treating.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>def add_job(\n    self, json_dict: dict, status_msg_dict: dict\n) -&gt; tuple[ResultDict, dict]:\n    \"\"\"\n    The function that translates the json with the instructions into some circuit and executes it.\n    It performs several checks for the job to see if it is properly working.\n    If things are fine the job gets added the list of things that should be executed.\n\n    json_dict: The job dictonary of all the instructions.\n    status_msg_dict: the status dictionary of the job we are treating.\n    \"\"\"\n    job_id = status_msg_dict[\"job_id\"]\n\n    result_dict: ResultDict = {\n        \"display_name\": self.display_name,\n        \"backend_version\": self.version,\n        \"job_id\": job_id,\n        \"qobj_id\": None,\n        \"success\": True,\n        \"status\": \"finished\",\n        \"header\": {},\n        \"results\": [],\n    }\n    err_msg, json_is_fine = self.check_json_dict(json_dict)\n    if json_is_fine:\n        # check_hilbert_space_dimension\n        dim_err_msg, dim_ok = self.check_dimension(json_dict)\n        if dim_ok:\n            for exp in json_dict:\n                exp_dict = {exp: json_dict[exp]}\n                # Here we\n                result_dict[\"results\"].append(self.gen_circuit(exp_dict))\n\n            status_msg_dict[\n                \"detail\"\n            ] += \"; Passed json sanity check; Compilation done. Shots sent to solver.\"\n            status_msg_dict[\"status\"] = \"DONE\"\n            return result_dict, status_msg_dict\n\n        status_msg_dict[\"detail\"] += (\n            \"; Failed dimensionality test. Too many atoms. File will be deleted. Error message : \"\n            + dim_err_msg\n        )\n        status_msg_dict[\"error_message\"] += (\n            \"; Failed dimensionality test. Too many atoms. File will be deleted. Error message :  \"\n            + dim_err_msg\n        )\n        status_msg_dict[\"status\"] = \"ERROR\"\n        return result_dict, status_msg_dict\n    else:\n        status_msg_dict[\"detail\"] += (\n            \"; Failed json sanity check. File will be deleted. Error message : \"\n            + err_msg\n        )\n        status_msg_dict[\"error_message\"] += (\n            \"; Failed json sanity check. File will be deleted. Error message : \"\n            + err_msg\n        )\n        status_msg_dict[\"status\"] = \"ERROR\"\n    return result_dict, status_msg_dict\n</code></pre>"},{"location":"utils/#src.sqooler.schemes.Spooler.check_dimension","title":"<code>check_dimension(json_dict)</code>","text":"<p>Make sure that the Hilbert space dimension is not too large.</p> <p>It can be implemented in the class that inherits, but it is not necessary. So this is only a placeholder.</p> <p>Parameters:</p> Name Type Description Default <code>json_dict</code> <code>dict</code> <p>the dictonary with the instructions</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>the error message</p> <code>bool</code> <code>bool</code> <p>is the dimension ok ?</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>def check_dimension(self, json_dict: dict) -&gt; tuple[str, bool]:\n    \"\"\"\n    Make sure that the Hilbert space dimension is not too large.\n\n    It can be implemented in the class that inherits, but it is not necessary.\n    So this is only a placeholder.\n\n    Args:\n        json_dict: the dictonary with the instructions\n\n    Returns:\n        str: the error message\n        bool: is the dimension ok ?\n    \"\"\"\n    # pylint: disable=W0613\n    return \"\", True\n</code></pre>"},{"location":"utils/#src.sqooler.schemes.Spooler.check_experiment","title":"<code>check_experiment(exper_dict)</code>","text":"<p>Check the validity of the experiment. This has to be implement in each subclass extra.</p> <p>Parameters:</p> Name Type Description Default <code>exper_dict</code> <code>dict</code> <p>The dictionary that contains the logic and should be verified.</p> required Source code in <code>src/sqooler/schemes.py</code> <pre><code>def check_experiment(self, exper_dict: dict) -&gt; tuple[str, bool]:\n    \"\"\"\n    Check the validity of the experiment.\n    This has to be implement in each subclass extra.\n\n    Args:\n        exper_dict: The dictionary that contains the logic and should\n            be verified.\n    \"\"\"\n    raise NotImplementedError(\"Subclasses should implement this!\")\n</code></pre>"},{"location":"utils/#src.sqooler.schemes.Spooler.check_instructions","title":"<code>check_instructions(ins_list)</code>","text":"<p>Check all the instruction to make sure that they are valid.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>def check_instructions(self, ins_list: list) -&gt; tuple[str, bool]:\n    \"\"\"\n    Check all the instruction to make sure that they are valid.\n    \"\"\"\n    err_code = \"\"\n    exp_ok = False\n    for ins in ins_list:\n        try:\n            gate_dict = gate_dict_from_list(ins)\n            self.ins_schema_dict[ins[0]](**gate_dict)\n            exp_ok = True\n        except ValidationError as err:\n            err_code = \"Error in instruction \" + str(err)\n            exp_ok = False\n        if not exp_ok:\n            break\n    return err_code, exp_ok\n</code></pre>"},{"location":"utils/#src.sqooler.schemes.Spooler.check_json_dict","title":"<code>check_json_dict(json_dict)</code>","text":"<p>Check if the json file has the appropiate syntax.</p> <p>Parameters:</p> Name Type Description Default <code>json_dict</code> <code>dict</code> <p>the dictonary that we will test.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>tuple[str, bool]</code> <p>is the expression having the appropiate syntax ?</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>def check_json_dict(self, json_dict: dict) -&gt; tuple[str, bool]:\n    \"\"\"\n    Check if the json file has the appropiate syntax.\n\n    Args:\n        json_dict (dict): the dictonary that we will test.\n\n    Returns:\n        bool: is the expression having the appropiate syntax ?\n    \"\"\"\n    for expr in json_dict:\n        err_code = \"Wrong experiment name or too many experiments\"\n        # Fix this pylint issue whenever you have time, but be careful !\n        # pylint: disable=W0702\n        try:\n            exp_ok = (\n                expr.startswith(\"experiment_\")\n                and expr[11:].isdigit()\n                and (int(expr[11:]) &lt;= self.n_max_experiments)\n            )\n        except:\n            exp_ok = False\n            break\n        if not exp_ok:\n            break\n        # test the structure of the experiment\n        err_code, exp_ok = self.check_experiment(json_dict[expr])\n        if not exp_ok:\n            break\n        # time to check the structure of the instructions\n        ins_list = json_dict[expr][\"instructions\"]\n        err_code, exp_ok = self.check_instructions(ins_list)\n        if not exp_ok:\n            break\n    return err_code.replace(\"\\n\", \"..\"), exp_ok\n</code></pre>"},{"location":"utils/#src.sqooler.schemes.Spooler.get_configuration","title":"<code>get_configuration()</code>","text":"<p>Sends back the configuration dictionary of the spooler.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>def get_configuration(self) -&gt; dict:\n    \"\"\"\n    Sends back the configuration dictionary of the spooler.\n    \"\"\"\n    gate_list = []\n    for _, ins_obj in self.ins_schema_dict.items():\n        if \"is_gate\" in ins_obj.model_fields:\n            gate_list.append(ins_obj.config_dict())\n    return {\n        \"description\": self.description,\n        \"version\": self.version,\n        \"cold_atom_type\": self.cold_atom_type,\n        \"gates\": gate_list,\n        \"max_experiments\": self.n_max_experiments,\n        \"max_shots\": self.n_max_shots,\n        \"simulator\": True,\n        \"supported_instructions\": list(self.ins_schema_dict.keys()),\n        \"num_wires\": self.n_wires,\n        \"wire_order\": self.wire_order,\n        \"num_species\": self.num_species,\n    }\n</code></pre>"},{"location":"utils/#src.sqooler.schemes.create_memory_data","title":"<code>create_memory_data(shots_array, exp_name, n_shots)</code>","text":"<p>The function to create memory key in results dictionary with proprer formatting.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>def create_memory_data(\n    shots_array: list, exp_name: str, n_shots: int\n) -&gt; ExperimentDict:\n    \"\"\"\n    The function to create memory key in results dictionary\n    with proprer formatting.\n    \"\"\"\n    exp_sub_dict: ExperimentDict = {\n        \"header\": {\"name\": \"experiment_0\", \"extra metadata\": \"text\"},\n        \"shots\": 3,\n        \"success\": True,\n        \"data\": {\"memory\": None},\n    }\n\n    exp_sub_dict[\"header\"][\"name\"] = exp_name\n    exp_sub_dict[\"shots\"] = n_shots\n    memory_list = [\n        str(shot).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")\n        for shot in shots_array\n    ]\n    exp_sub_dict[\"data\"][\"memory\"] = memory_list\n    return exp_sub_dict\n</code></pre>"},{"location":"utils/#src.sqooler.schemes.gate_dict_from_list","title":"<code>gate_dict_from_list(inst_list)</code>","text":"<p>Transforms a list into an appropiate dictionnary for instructions.</p> Source code in <code>src/sqooler/schemes.py</code> <pre><code>def gate_dict_from_list(inst_list: list) -&gt; dict:\n    \"\"\"\n    Transforms a list into an appropiate dictionnary for instructions.\n    \"\"\"\n    return {\"name\": inst_list[0], \"wires\": inst_list[1], \"params\": inst_list[2]}\n</code></pre>"}]}